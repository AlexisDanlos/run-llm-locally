# Local LLM Runner

A Flutter application that allows you to run Large Language Models (LLMs) directly on your device.

## Features

- Run LLMs locally without internet connection
- Simple and intuitive chat interface
- Supports multiple platforms (Android, iOS, Windows, macOS, Linux)

## Getting Started

1. Clone this repository
2. Make sure you have Flutter installed
3. Run `flutter pub get` to install dependencies
4. Place your model file in the `assets` folder
5. Run the app using `flutter run`

## Requirements

- Flutter SDK
- Device with sufficient RAM to run LLMs
- Compatible model file (.bin or .gguf format)

## License

This project is open source. Feel free to use and modify as needed.
